{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "## Quick refresher\n",
    "\n",
    "The general form of a multivariate regression is\n",
    "\n",
    "$$\n",
    "y \\approx w_{0} +\n",
    "w_{1} x_{1} + w_{2} x_{2} + \\cdots + w_{p}x_p\n",
    "$$\n",
    "\n",
    "where $y$ is the response vector and $x_{1},…,x_{p}$ are the features (covariates). \n",
    "Each of the predictor variables must be numerical. \n",
    "The parameters (coefficients) $w_0,…,w_p$ correspond to the *effect* of each feature after taking account of the effect of all other features in the model. \n",
    "\n",
    "It is convenient to write this in matrix form where all the values of the forecast variable are given in a single equation. \n",
    "\n",
    "$$\n",
    "X = \\left[\\begin{matrix} 1 & x_{1,1} & x_{2,1} & \\dots & x_{p,1}\\\\ 1 & x_{1,2} & x_{2,2} & \\dots & x_{p,2}\\\\ \\vdots & \\vdots & \\vdots & & \\vdots\\\\ 1 & x_{1,n} & x_{2,n} & \\dots & x_{p,n} \\end{matrix}\\right].\n",
    "$$\n",
    "\n",
    "The first column correspond to the intercept ($w_0$) which does not multiply a feature.\n",
    "\n",
    "The problem then becomes one of finding $w\\in\\mathbb R^p$ such that $y\\approx Xw$ or, in other words,\n",
    "\n",
    "$$\n",
    "w^\\star \\quad\\!\\!=\\quad\\!\\! \\arg\\min_w\\|y-Xw\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data + first look\n",
    "\n",
    "* Load the data `bikes.csv`, have a look at it, \n",
    "* extract the columns `temperature`, `humidity` and `windspeed` to form the feature matrix\n",
    "* extract the column `count` to form the response matrix\n",
    "\n",
    "**Note**: you do not need to add a column of $1$ to the feature matrix, this is done automatically by Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the data and extract the feature matrix and the response as matrices/vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a scatter matrix to have a look at the data, what can you observe?\n",
    "\n",
    "**Note** you can use [pandas' scatter matrix](https://pandas.pydata.org/pandas-docs/stable/visualization.html#scatter-plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here to show a scatter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last rows shows the relation between each feature and the number of bikes hired per day. \n",
    "It's hard to see any particular pattern in humidity and windspeed, while temperature definitely has a strong relation with the bikes hired.\n",
    "\n",
    "Display the correlation coefficient (use `np.corrcoef`) between each of the three covariates and the response. \n",
    "(Cf [the documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html) for `corrcoef`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficients confirm that the number of bikes hired is strongly correlated with the temperature. There also seems to be a smaller effect for humidity and windspeed. \n",
    "This makes sense intuitively; the better the weather is, the more likely people will want to go cycling. \n",
    "Now that you have a “feel” for the relationships between the two features and the response variable, you have a frame of reference when developing the regression model.\n",
    "\n",
    "## Fitting a linear regression\n",
    "\n",
    "Sklearn offers the `LinearRegression` from `sklearn.linear_model`. \n",
    "(Note that `sklearn.linear_model` has **a lot** of models to offer a few of which we will cover). \n",
    "Import it and have a look at the documentation using the question mark. \n",
    "Then, create an instance, fit it (on the whole data, exceptionally we will ignore the train-test-split step). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here to apply and fit a linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the coefficients \n",
    "\n",
    "* `.coef_` will give you the coefficients for the actual covariates ($w_1, \\dots, w_p$)\n",
    "* `.intercept_` will give you the coefficient for the bias term ($w_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code to display the coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the model match the data well?\n",
    "\n",
    "You can get the model to predict values you may be interested in using the `.predict`. For example, what does your model suggest for the number of bikes hired at 20 degrees, 60% humidity and normalised windspeed 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get `y_pred`, the prediction on the original data. Then display \n",
    "\n",
    "* the true counts vs the temperature\n",
    "* the predicted counts vs the temperature\n",
    "\n",
    "does it work well? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that the model picks up a trend but the model is likely too simple to really capture the information contained in the data. \n",
    "\n",
    "**Question**: why are the predictions not on a straight line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals diagnostic\n",
    "\n",
    "When a Linear regression model is properly working we have that the difference between predictions and targets should not present any particular structure. To study this, we introduce the concept of residual. A residual can be defined as follows:\n",
    "\n",
    "$$\n",
    "r = y-\\hat y\n",
    "$$\n",
    "\n",
    "Where $\\hat y$ is the prediction made by the model and $y$ is the response.\n",
    "\n",
    "Have a look for the bike dataset, what do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add your code to display the residuals vs the response \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at another dataset\n",
    "\n",
    "We will re-do these steps with a few variations on a different dataset.\n",
    "\n",
    "Load the `auto.csv` dataset, note that the missing values are encoded as `?` and should be dropped. Extract the columns `displacement`, `horsepower` and `weight` for the feature matrix and `mpg` as the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a linear model, specify `normalize=True` so that the data is scaled before applying the regression and compute the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot of the residuals against the fitted values should show no pattern. \n",
    "If a pattern is observed, it means that the model is not able to fully capture the information in the data. \n",
    "To overcome this problem, a transformation of the forecast variable (such as a log transformation) may help.\n",
    "\n",
    "Plot the residuals against the response and discuss whether there is a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot seems to show a systematic pattern as the variation in the residuals changes with the response, additionally there seems to be an upward pattern. \n",
    "\n",
    "To explore this further, we can do a scatterplot of the residuals against each predictor in the model to test whether a pattern can be observed there.\n",
    "If these scatterplots show a pattern, the relationship may be nonlinear (or better explained by a nonlinear model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the scatterplots of the residuls vs the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding non-linear features\n",
    "\n",
    "The charts suggest a nonlinear relationship between the features and the residuals. \n",
    "One thing we could do is add transformed features. \n",
    "For example the log of the features (note that all the features are positive so this does not cause issues).  \n",
    "\n",
    "The first part of the cell is a **FeatureUnion**, it allows to combine derived features. \n",
    "It is extremely convenient and, combined with **Pipeline** can bring a lot of flexibility to your models. \n",
    "This will be covered in much more details tomorrow, for now try to get an intuition for what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "feat_union = FeatureUnion([\n",
    "    ('identity', FunctionTransformer()),\n",
    "    ('log-transform', FunctionTransformer(np.log))])\n",
    "\n",
    "X2 = feat_union.fit_transform(X)\n",
    "\n",
    "print(\"Before: {}\".format(X.shape))\n",
    "print(\"After: {} (with log features)\".format(X2.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an extended dataset, fit a Linear regression again.\n",
    "The model now looks like:\n",
    "   \n",
    "\\begin{eqnarray}\n",
    "\\text{mpg} &=& w_0 + w_1 \\times \\text{displacement} + w_2\\times \\text{horsepower} + w_3\\times \\text{weight}+\\\\\n",
    "&& w_4\\times\\log(\\text{displacement}) + w_5\\times\\log(\\text{horsepower}) + w_6\\times\\log(\\text{weight})\n",
    "\\end{eqnarray}\n",
    "\n",
    "Apply this model (with normalisation) and show the scatterplots of the residuals vs each feature + vs the response. What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of the residuals vs features, it clearly looks better in terms of the *trend*. The residuals still seem to show a pattern vs the response but much decreased.\n",
    "\n",
    "Something to note here is that the **variance** of the residuals seems to be correlated with the features. This also indicates that the model doesn't fully capture the information in the data.\n",
    "\n",
    "More could be done to try to get a better model but, by now, you should have an idea for what goes on when fitting a regression model and trying to assess its quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality assessment: the R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen, the R-squared (R2) is a measure of fit quality when applying a linear regression.\n",
    "It is obtained by comparing the RSS to the TSS:\n",
    "\n",
    "$$\n",
    "R^2 = 1-{RSS \\over TSS}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* the RSS is the squared norm of the residual vector\n",
    "* the TSS is the squared norm of the centered response vector \n",
    "\n",
    "**Tasks**\n",
    "\n",
    "* compute the RSS\n",
    "* compute the TSS\n",
    "* compute the R2 (you should get something around `0.7`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric is fairly easy to interpret:\n",
    "\n",
    "- it's close to 1 if the model explains much of the variance.\n",
    "- it's close to 0 if the model explains little of the variance.\n",
    "\n",
    "***Question***: can this value be negative or more than 1?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
